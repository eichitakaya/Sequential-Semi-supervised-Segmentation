{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import cv2\n",
    "import torch_networks as networks\n",
    "import torchvision.transforms.functional as TF\n",
    "import augmentation.transform_functions as transform_functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def left_shift(model, image_tensor, shift_pixels):\n",
    "    image = transform_functions.left_shift(image_tensor, shift_pixels, inference=True)\n",
    "    predict = model(image)\n",
    "    # 推論結果をさらに反転\n",
    "    predict = transform_functions.right_shift(predict, shift_pixels, inference=True)\n",
    "    return predict\n",
    "\n",
    "def gaussian_noise(image_tensor):\n",
    "    image = transform_functions.gaussian_noise(image_tensor)\n",
    "    predict = image\n",
    "    return predict\n",
    "\n",
    "def gaussian_blur(image_tensor):\n",
    "    image = transform_functions.gaussian_blur(image_tensor)\n",
    "    predict = image\n",
    "    return predict\n",
    "\n",
    "def high_contrast(image_tensor):\n",
    "    #print(image_tensor.max(), image_tensor.min())\n",
    "    image = transform_functions.high_contrast(image_tensor)\n",
    "    #predict = model(image)\n",
    "    predict = image\n",
    "    #print(predict.max(), predict.min())\n",
    "    return predict\n",
    "\n",
    "def low_contrast(image_tensor):\n",
    "    #print(image_tensor.max(), image_tensor.min())\n",
    "    image = transform_functions.low_contrast(image_tensor)\n",
    "    #predict = model(image)\n",
    "    predict = image\n",
    "    #print(predict.max(), predict.min())\n",
    "    return predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[176., 176., 176.,  ..., 206., 206., 206.],\n",
      "          [176., 176., 176.,  ..., 206., 206., 206.],\n",
      "          [176., 176., 176.,  ..., 206., 206., 205.],\n",
      "          ...,\n",
      "          [ 44.,  44.,  44.,  ..., 161., 161., 160.],\n",
      "          [ 48.,  48.,  48.,  ..., 152., 152., 152.],\n",
      "          [223., 223., 224.,  ..., 244., 244., 244.]]]])\n",
      "tensor([[[[167.2000, 167.2000, 167.2000,  ..., 195.7000, 195.7000, 195.7000],\n",
      "          [167.2000, 167.2000, 167.2000,  ..., 195.7000, 195.7000, 195.7000],\n",
      "          [167.2000, 167.2000, 167.2000,  ..., 195.7000, 195.7000, 194.7500],\n",
      "          ...,\n",
      "          [ 41.8000,  41.8000,  41.8000,  ..., 152.9500, 152.9500, 152.0000],\n",
      "          [ 45.6000,  45.6000,  45.6000,  ..., 144.4000, 144.4000, 144.4000],\n",
      "          [211.8500, 211.8500, 212.8000,  ..., 231.8000, 231.8000, 231.8000]]]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# takaya.jpgをグレースケールで読み込みtensorに変換\n",
    "image = cv2.imread(\"takaya.jpg\")\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "image = torch.from_numpy(image)\n",
    "# float32に変換\n",
    "image = image.float()\n",
    "# 4次元に変換\n",
    "image = image.unsqueeze(0)\n",
    "image = image.unsqueeze(0)\n",
    "print(image)\n",
    "#result = inference_time_augmentation(model, image, method=\"vote\")\n",
    "result = low_contrast(image)\n",
    "# resultを画像として保存\n",
    "print(result)\n",
    "result = result.detach().numpy()\n",
    "result = result[0][0]\n",
    "result = result.astype(np.uint8)\n",
    "cv2.imwrite(\"aug_test_img/low_contrast.jpg\", result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
