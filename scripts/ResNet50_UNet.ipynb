{"cells":[{"cell_type":"markdown","source":["#importとseedに固定"],"metadata":{"id":"iQKQv3lE-wXM"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"FfsTMOL6MLzx"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torchvision\n","from torchvision import models, transforms\n","import torchmetrics\n","from torchmetrics.functional import accuracy\n","from PIL import Image\n","import numpy as np\n","from glob import glob\n","import glob\n","import re\n","import cv2\n","from tqdm import tqdm as tqdm\n","import statistics\n","import os\n","import json\n","import datetime\n","import matplotlib.pyplot as plt\n","import matplotlib.ticker as ticker\n","from torch.optim.lr_scheduler import StepLR"]},{"cell_type":"code","source":["#seedの固定\n","def fix_seed(seed):\n","    # Numpy\n","    np.random.seed(seed)\n","    # Pytorch\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed_all(seed)\n","    torch.backends.cudnn.deterministic = True\n","\n","SEED = 1\n","fix_seed(SEED)"],"metadata":{"id":"kKsEJKj8_EJr"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#データセットの定義"],"metadata":{"id":"TwuBQMKp_RLu"}},{"cell_type":"code","source":["#512to256の画像をリストに取得\n","Tr_image = [p for p in glob.glob('../../data/MLO_dataset/512to256DS/Tr_image/*/*.png', recursive=True)\n","       if re.findall('png', p)]\n","Tr_label = [p for p in glob.glob('../../data/MLO_dataset/512to256DS/Tr_label/*/*.png', recursive=True)\n","       if re.findall('png', p)]\n","Va_image = [p for p in glob.glob('../../data/MLO_dataset/512to256DS/Va_image/*/*.png', recursive=True)\n","       if re.findall('png', p)]\n","Va_label = [p for p in glob.glob('../../data/MLO_dataset/512to256DS/Va_label/*/*.png', recursive=True)\n","       if re.findall('png', p)]\n","Te_image = [p for p in glob.glob('../../data/MLO_dataset/512to256DS/Te_image/*/*.png', recursive=True)\n","       if re.findall('png', p)]\n","Te_label = [p for p in glob.glob('../../data/MLO_dataset/512to256DS/Te_label/*/*.png', recursive=True)\n","       if re.findall('png', p)]\n","\n","#取得した画像のリストを辞書に格納\n","tvt_image = {'Tr':Tr_image,'Va':Va_image,'Te':Te_image}\n","tvt_label = {'Tr':Tr_label,'Va':Va_label,'Te':Te_label}"],"metadata":{"id":"Li9-EBZr_L6N","executionInfo":{"status":"ok","timestamp":1667369882251,"user_tz":-540,"elapsed":6,"user":{"displayName":"八島拓海","userId":"14182190342367427561"}}},"execution_count":1,"outputs":[]},{"cell_type":"code","source":["#前処理\n","\n","# 256×256,16bit,png形式の原画像をtorch型,3チャンネル形式に変換\n","class Dataset_16bit(torch.utils.data.Dataset):\n","\n","    def __init__(self, mode):\n","        self.images = sorted(tvt_image[mode])        \n","        self.labels = sorted(tvt_label[mode])\n","        \n","    def __getitem__(self, idx):\n","        image_path = self.images[idx]\n","        image = cv2.imread(image_path, cv2.IMREAD_ANYDEPTH | cv2.IMREAD_ANYCOLOR) #16bitで読み込む\n","        image = cv2.cvtColor(image, cv2.COLOR_GRAY2RGB) #3チャンネルに変換\n","        image = image[16:240, 16:240] #中心の224×２２４に切り取る\n","        image = image/65535 #0~65535を０〜１に変換\n","        image = image.astype(np.float32) #float型に変換\n","        image = torch.from_numpy(image).clone() #torchに変換\n","        image = image.permute((2, 0, 1)) #順番を修正　(H,W,C) → (C,H,W)\n","\n","        label_path = self.labels[idx]\n","        label = Image.open(label_path)\n","        label = np.array(label) #numpy型に変換\n","        label = label[16:240, 16:240] #中心の224×２２４に切り取る\n","        label = label/255\n","        label = torch.tensor(label, dtype=torch.float32) #float型に変換\n","        return image, label\n","\n","    def __len__(self):\n","        return len(self.images)"],"metadata":{"id":"YLR7h5wI_VyE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# データセットの取得\n","train = Dataset_16bit('Tr')\n","val = Dataset_16bit('Va')\n","test = Dataset_16bit('Te')\n","\n","# バッチサイズの定義\n","batch_size = 16\n","\n","# Data Loader を定義\n","train_loader = torch.utils.data.DataLoader(train, batch_size, shuffle=True, drop_last=True)\n","val_loader = torch.utils.data.DataLoader(val, batch_size, shuffle=True, drop_last=True)\n","test_loader = torch.utils.data.DataLoader(test, batch_size)"],"metadata":{"id":"vc4zkozQ_X1k"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#損失関数とIoUの定義"],"metadata":{"id":"M80xB-7P_by2"}},{"cell_type":"code","source":["#PyTorch DiceLossを定義\n","class DiceLoss(nn.Module):\n","    def __init__(self, weight=None, size_average=True):\n","        super(DiceLoss, self).__init__()\n","\n","    def forward(self, inputs, targets, smooth=1):\n","        \n","        #comment out if your model contains a sigmoid or equivalent activation layer\n","        inputs = F.sigmoid(inputs)       \n","        \n","        #flatten label and prediction tensors\n","        inputs = inputs.view(-1)\n","        targets = targets.view(-1)\n","        \n","        intersection = (inputs * targets).sum() #「正解」かつ「出力結果」のピクセル数を算出\n","        dice = (2.*intersection + smooth)/(inputs.sum() + targets.sum() + smooth) #(「正解」かつ「出力結果」)/(「正解」と「出力結果」の平均の大きさ)   \n","        \n","        return 1 - dice"],"metadata":{"id":"HdjG9lz4_Zt1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#IoUを定義\n","def iou_score(output, target):\n","    smooth = 1e-5\n","\n","    if torch.is_tensor(output):\n","        output = torch.sigmoid(output).data.cpu().numpy()\n","    if torch.is_tensor(target):\n","        target = target.data.cpu().numpy()\n","        \n","    output = output > 0.5 #閾値の設定\n","    target = target > 0.5\n","    intersection = (output & target).sum()\n","    union = (output | target).sum()\n","\n","    return (intersection + smooth) / (union + smooth)"],"metadata":{"id":"I05_OqZO_hRt"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#ResNet50をbackbornとしたUNetの定義"],"metadata":{"id":"CKknqpbM_kQD"}},{"cell_type":"code","source":["class ConvBlock(nn.Module):\n","    \"\"\"\n","    入出力チャンネル数を引数に取り、Conv -> BN -> ReLU　を実行する。\n","    \"\"\"\n","\n","    def __init__(self, in_channels, out_channels, padding=1, kernel_size=3, stride=1, with_nonlinearity=True):\n","        super().__init__()\n","        self.conv = nn.Conv2d(in_channels, out_channels, padding=padding, kernel_size=kernel_size, stride=stride)\n","        self.bn = nn.BatchNorm2d(out_channels)\n","        self.relu = nn.ReLU()\n","        self.with_nonlinearity = with_nonlinearity\n","\n","    def forward(self, x):\n","        x = self.conv(x)\n","        x = self.bn(x)\n","        if self.with_nonlinearity:\n","            x = self.relu(x)\n","        return x\n","\n","\n","class Bridge(nn.Module):\n","    \"\"\"\n","    UNetのエンコーダーとデコーダーを繋ぐ部分\n","    \"\"\"\n","\n","    def __init__(self, in_channels, out_channels):\n","        super().__init__()\n","        self.bridge = nn.Sequential(\n","            ConvBlock(in_channels, out_channels),\n","            ConvBlock(out_channels, out_channels)\n","        )\n","\n","    def forward(self, x):\n","        return self.bridge(x)\n","\n","\n","class UpBlockForUNetWithResNet50(nn.Module):\n","    \"\"\"\n","    Up block that encapsulates one up-sampling step which consists of Upsample -> ConvBlock -> ConvBlock\n","    \"\"\"\n","\n","    def __init__(self, in_channels, out_channels, up_conv_in_channels=None, up_conv_out_channels=None,\n","                 upsampling_method=\"conv_transpose\"):\n","        super().__init__()\n","\n","        if up_conv_in_channels == None:\n","            up_conv_in_channels = in_channels\n","        if up_conv_out_channels == None:\n","            up_conv_out_channels = out_channels\n","\n","        if upsampling_method == \"conv_transpose\":\n","            self.upsample = nn.ConvTranspose2d(up_conv_in_channels, up_conv_out_channels, kernel_size=2, stride=2)\n","        elif upsampling_method == \"bilinear\":\n","            self.upsample = nn.Sequential(\n","                nn.Upsample(mode='bilinear', scale_factor=2),\n","                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1)\n","            )\n","        self.conv_block_1 = ConvBlock(in_channels, out_channels)\n","        self.conv_block_2 = ConvBlock(out_channels, out_channels)\n","\n","    def forward(self, up_x, down_x):\n","        \"\"\"\n","        :param up_x: this is the output from the previous up block\n","        :param down_x: this is the output from the down block\n","        :return: upsampled feature map\n","        \"\"\"\n","        x = self.upsample(up_x)\n","        x = torch.cat([x, down_x], 1)\n","        x = self.conv_block_1(x)\n","        x = self.conv_block_2(x)\n","        return x\n","\n","\n","class UNetWithResnet50Encoder(nn.Module):\n","    DEPTH = 6\n","\n","    def __init__(self, n_classes=1):\n","        super().__init__()\n","        resnet = torchvision.models.resnet.resnet50(pretrained=False) #エンコーダー部分は既存のResNet50を読み込む\n","        down_blocks = []\n","        up_blocks = []\n","        self.input_block = nn.Sequential(*list(resnet.children()))[:3]\n","        self.input_pool = list(resnet.children())[3]\n","        for bottleneck in list(resnet.children()):\n","            if isinstance(bottleneck, nn.Sequential):\n","                down_blocks.append(bottleneck)\n","        self.down_blocks = nn.ModuleList(down_blocks)\n","        self.bridge = Bridge(2048, 2048)\n","        up_blocks.append(UpBlockForUNetWithResNet50(2048, 1024))\n","        up_blocks.append(UpBlockForUNetWithResNet50(1024, 512))\n","        up_blocks.append(UpBlockForUNetWithResNet50(512, 256))\n","        up_blocks.append(UpBlockForUNetWithResNet50(in_channels=128 + 64, out_channels=128,\n","                                                    up_conv_in_channels=256, up_conv_out_channels=128))\n","        up_blocks.append(UpBlockForUNetWithResNet50(in_channels=64 + 3, out_channels=64,\n","                                                    up_conv_in_channels=128, up_conv_out_channels=64))\n","\n","        self.up_blocks = nn.ModuleList(up_blocks)\n","\n","        self.out = nn.Conv2d(64, n_classes, kernel_size=1, stride=1)\n","\n","    def forward(self, x, with_output_feature_map=False):\n","        pre_pools = dict()\n","        pre_pools[f\"layer_0\"] = x\n","        x = self.input_block(x)\n","        pre_pools[f\"layer_1\"] = x\n","        x = self.input_pool(x)\n","\n","        for i, block in enumerate(self.down_blocks, 2):\n","            x = block(x)\n","            if i == (UNetWithResnet50Encoder.DEPTH - 1):\n","                continue\n","            pre_pools[f\"layer_{i}\"] = x\n","\n","        x = self.bridge(x)\n","\n","        for i, block in enumerate(self.up_blocks, 1):\n","            key = f\"layer_{UNetWithResnet50Encoder.DEPTH - 1 - i}\"\n","            x = block(x, pre_pools[key])\n","        output_feature_map = x\n","        x = self.out(x)\n","        del pre_pools\n","        if with_output_feature_map:\n","            return x, output_feature_map\n","        else:\n","            return x\n","        \n","if __name__ == '__main__':\n","    image = torch.rand((1, 3, 224, 224))\n","    model = UNetWithResnet50Encoder()\n","    model(image)\n","\n","#https://github.com/kevinlu1211/pytorch-unet-resnet-50-encoder/blob/master/u_net_resnet_50_encoder.py\n","#↑参考にしたサイト"],"metadata":{"id":"CbXszvwj_jCs","executionInfo":{"status":"ok","timestamp":1667369965869,"user_tz":-540,"elapsed":294,"user":{"displayName":"八島拓海","userId":"14182190342367427561"}}},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":["#学習済みパラメータを読み込み、置き換える。"],"metadata":{"id":"BcOJzwDK_tKF"}},{"cell_type":"code","source":["#deviceの確認\n","device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n","device"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":208},"id":"ERg7l9qw_r0v","executionInfo":{"status":"error","timestamp":1667370011172,"user_tz":-540,"elapsed":17,"user":{"displayName":"八島拓海","userId":"14182190342367427561"}},"outputId":"a9f9c373-90e7-4934-b101-8afd838b3705"},"execution_count":2,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-2-ec2029208a54>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#deviceの確認\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cuda:0'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'cpu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"]}]},{"cell_type":"code","source":["#　置き換える関数を定義\n","def Convert(model, pre_param, seg_param):\n","    pre_key = list(pre_param.keys())\n","    seg_key = list(seg_param.keys())\n","    for n in range(318): #ResNet50の入力から318個目までのパラメータを使う。\n","        seg_param[seg_key[n]] = pre_param[pre_key[n]]\n","        model.load_state_dict(seg_param)\n","        #print(seg_key[n] + 'を置き換えました。')"],"metadata":{"id":"6WN7KYCn_0eK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#　パラメータの置き換え\n","SEED = 1\n","fix_seed(SEED)\n","\n","net = UNetWithResnet50Encoder().to(device) #モデルの読み込み(初期値)\n","Seg_param = net.state_dict() #今から置き換えられる重み\n","pre_param = torch.load('../../parameter/Fractal/RadImageNet_ResNet50_torch_2.pth') #新しく置き換える重み\n","Convert(net, pre_param, Seg_param) #「net」の重みが置き換えられる"],"metadata":{"id":"leNQ13iI_2k6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#　置き換わっているかの確認 (一緒だったら置き換え成功)\n","new_param = net.state_dict()\n","print(new_param['input_block.0.weight'][0])\n","print(pre_param['conv1.weight'][0])"],"metadata":{"id":"zEadCC_l_4Lh"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#学習"],"metadata":{"id":"v7nhlQ5V_7my"}},{"cell_type":"code","source":["SEED = 1\n","fix_seed(SEED)\n","\n","#パラメータを置き換えたモデルを読み込む\n","model = net\n","\n","#ハイパーパラメータの設定\n","max_epochs = 30 # 学習繰り返し回数\n","lr = 0.001 #learning_rate\n","\n","param_savedir = \"\"\n","param_savedir_last = \"\"\n","figure_savedir = \"\"\n","LossAcc_savedir = \"\"\n","\n","diceloss = DiceLoss() #損失関数はDiceloss\n","iou = iou_score #評価指標はIoU\n","optimizer = torch.optim.Adam(model.parameters(), lr=lr) #optimizerはAdam\n","scheduler = StepLR(optimizer, step_size=10, gamma=0.1) #10エポックごとに学習率を1/10にさせる"],"metadata":{"id":"Jjd3Zvwi_6Dm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n","time_start = datetime.datetime.now()\n","print('train', time_start)\n","\n","#確認用のtrainとvalのloss,IoUを入れるリスト\n","total_train_loss = []\n","total_train_iou = []\n","total_valid_loss = []\n","total_valid_iou = []\n","epoch = []\n","\n","#初期値。以降エポックごとにValのiouを算出し、前のエポックと比較してiourateが大きくなればモデルを保存する。\n","iourate = 0\n","\n","for iepoch in range(max_epochs):\n","    #学習率変更の設定\n","    #scheduler.step() #学習率を変更する時に使う\n"," \n","   #訓練の定義\n","    train_loss_list = [] #繰り返しごとのtrain_lossを入れるリストを作成 \n","    train_IoU_list = [] #繰り返しごとのtrain_IoUを入れるリストを作成\n","    model.train() #学習モード\n","    pbar = tqdm(train_loader, desc = 'description')\n","    for x_train, t_train in pbar:\n","        # toGPU (CPUの場合はtoCPU)\n","        x = x_train.to(device)\n","        t = t_train.to(device)\n","        optimizer.zero_grad()\n","        #　推定\n","        y = model.forward(x) # y.shape = (batch_size, 1, 224, 224)\n","        y = y.view(-1, 224, 224) #torch.Size([8, 224, 224]) torch.float32\n","        #　損失計算\n","        train_loss = diceloss(y,t)\n","        train_loss.backward() # backward (勾配計算)\n","        #精度評価\n","        train_iou = iou(y,t)\n","        train_loss_list.append(train_loss.item()) #lossを取得したリストに追加する。\n","        train_IoU_list.append(train_iou.item()) #iouを取得したリストに追加する。\n","        optimizer.step() # パラメータの微小移動\n","        pbar.set_description(f\"Epoch: {iepoch+1}\")\n","\n","    #検証の定義\n","    val_loss_list = [] #繰り返しごとのval_lossを入れるリストを作成\n","    val_IoU_list = [] #繰り返しごとのval_IoUを入れるリストを作成\n","    with torch.no_grad():\n","        model.eval() #検証モード\n","        for val_x,val_t in val_loader:\n","            val_x,val_t = val_x.to(device),val_t.to(device)\n","\n","            #順伝搬の計算\n","            val_y = model(val_x)\n","            val_y = val_y.view(-1, 224, 224) #torch.Size([8, 224, 224]) torch.float32\n","            #損失計算\n","            val_loss = diceloss(val_y,val_t).item()\n","            #精度評価\n","            val_iou = iou(val_y,val_t).item()\n","            val_loss_list.append(val_loss) #lossを取得したリストに追加する。\n","            val_IoU_list.append(val_iou) #iouを取得したリストに追加する。   \n","    \n","    #後でグラフにするためにlossとepoch数をリストに保存する。\n","    train_loss_mean = statistics.mean(train_loss_list) #train_lossのepochごとの平均を求める。\n","    total_train_loss.append(train_loss_mean)\n","    \n","    train_iou_mean = statistics.mean(train_IoU_list) #train_iouのepochごとの平均を求める。\n","    total_train_iou.append(train_iou_mean) \n","    \n","    val_loss_mean = statistics.mean(val_loss_list) #val_lossのepochごとの平均を求める。\n","    total_valid_loss.append(val_loss_mean)\n","    \n","    val_iou_mean = statistics.mean(val_IoU_list) #val_iouのepochごとの平均を求める。\n","    total_valid_iou.append(val_iou_mean)\n","    \n","    epoch.append(iepoch+1)\n","    \n","    #途中結果の表示とモデルの保存\n","    if iourate <= val_iou_mean: #このエポックのval_iouが、これまでのval_iouの最大値より小さくなれば「IoU向上」とプリントし、そのモデルを保存\n","            iourate = val_iou_mean #val_lossの最小値を更新しておく。\n","            coment = 'IoU向上!'\n","            torch.save(model.state_dict(), param_savedir) #同じ名前で保存し、更新のたびに上書きするようにする。 \n","            \n","    else: #val_iouが小さくなれば、更新せずに次のエポックへ\n","            coment = 'IoU低下,,,' #「IoU低下」とプリント\n","    \n","    print(f\"Train Loss: {total_train_loss[-1]}, Train IOU: {total_train_iou[-1]}\")\n","    print(f\"Valid Loss: {total_valid_loss[-1]}, Valid IOU: {total_valid_iou[-1]}, Validの{coment}\")\n","    \n","    #エポックごとに~_listを空にする。\n","    train_loss_list.clear() \n","    train_IoU_list.clear()\n","    val_loss_list.clear()\n","    val_IoU_list.clear()\n","\n","torch.save(model.state_dict(), param_savedir_last)\n","time_fin = datetime.datetime.now() \n","print(time_fin)\n","print('---------------------------------------------')"],"metadata":{"id":"-Sx4naUx__po"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#Loss,IoUの描画"],"metadata":{"id":"nt7rDN5IAEg3"}},{"cell_type":"code","source":["# グラフの表示(trainとval)\n","def writing_plot(history_tr, history_va, epoch):\n","    # プロット領域(Figure, Axes)の初期化\n","    fig = plt.figure(figsize=(20, 8))\n","    ax1 = fig.add_subplot(121)\n","    ax2 = fig.add_subplot(122)\n","    \n","    ax1.plot(range(1,epoch+1), history_tr['loss'], label='loss(train)')\n","    ax1.plot(range(1,epoch+1), history_va['loss'], label='loss(val)')\n","    ax1.set_xlim(1,epoch) #ax1.set_ylim(0,100)\n","    ax1.xaxis.set_major_locator(ticker.MultipleLocator(1))\n","    ax1.set_xlabel(\"epoch\")\n","    ax1.set_ylabel(\"loss\")\n","    ax1.set_title(\"model loss\")\n","    \n","    ax2.plot(range(1,epoch+1), history_tr['IoU'], label='IoU(train)')\n","    ax2.plot(range(1,epoch+1), history_va['IoU'], label='IoU(val)')\n","    ax2.set_xlim(1,epoch)\n","    ax2.set_ylim(0,1)\n","    ax2.xaxis.set_major_locator(ticker.MultipleLocator(1))\n","    ax2.set_xlabel(\"epoch\")\n","    ax2.set_ylabel(\"IoU\")\n","    ax2.set_title(\"model IoU\")\n","    \n","    ax1.legend()\n","    ax2.legend()\n","    plt.show()\n","    \n","    fig.savefig(figure_savedir, dpi=300)"],"metadata":{"id":"VeRnAjbOADLt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#epochごとのlossとiouを描画\n","history_tr = {'loss':total_train_loss, 'IoU':total_train_iou}\n","history_va = {'loss':total_valid_loss, 'IoU':total_valid_iou}\n","writing_plot(history_tr, history_va, max_epochs)"],"metadata":{"id":"W-tb3c3_AKHN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#epochごとのlossとiouの値の保存\n","history = {'Tr':history_tr, 'Va':history_va}\n","with open(LossAcc_savedir, 'w') as outfile:\n","        json.dump(history, outfile, indent=4)"],"metadata":{"id":"EWxTFKKUAL4v"},"execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"},"colab":{"provenance":[],"collapsed_sections":["Apn-qwmaMLz2","td8z1kvLMLz2"]}},"nbformat":4,"nbformat_minor":0}